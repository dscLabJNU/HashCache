{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "log_dir=\"../logs\"\n",
    "faascache=\"FaaSCache\"\n",
    "hashcache=\"HashCache\"\n",
    "openwhisk=\"OpenWhisk\"\n",
    "FaaSCache_data = pd.read_csv(f\"{log_dir}/{faascache}/{faascache}_stats.csv\")\n",
    "HashCache_data = pd.read_csv(f\"{log_dir}/{hashcache}/{hashcache}_stats.csv\")\n",
    "OpenWhisk_data = pd.read_csv(f\"{log_dir}/{openwhisk}/{openwhisk}_stats.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== reservation =====\n",
      "Average Response Time-latency:\n",
      " [146.51851852], [197.80701754], [217.15217391]\n",
      "Request Count-latency:\n",
      " [54], [57], [46]\n",
      "50%-latency:\n",
      " [17], [37], [36]\n",
      "75%-latency:\n",
      " [19], [52], [72]\n",
      "90%-latency:\n",
      " [58], [480], [450]\n",
      "95%-latency:\n",
      " [63], [520], [480]\n",
      "99%-latency:\n",
      " [6700], [5600], [5400]\n",
      "99.9%-latency:\n",
      " [6700], [5600], [5400]\n",
      "===== search =====\n",
      "Average Response Time-latency:\n",
      " [39.37142365], [304.76758024], [318.36188201]\n",
      "Request Count-latency:\n",
      " [5802], [5546], [5441]\n",
      "50%-latency:\n",
      " [17], [190], [190]\n",
      "75%-latency:\n",
      " [20], [290], [290]\n",
      "90%-latency:\n",
      " [23], [600], [600]\n",
      "95%-latency:\n",
      " [26], [670], [680]\n",
      "99%-latency:\n",
      " [330], [1100], [1100]\n",
      "99.9%-latency:\n",
      " [4900], [16000], [15000]\n",
      "===== user =====\n",
      "Average Response Time-latency:\n",
      " [287.02325581], [329.5], [192.09259259]\n",
      "Request Count-latency:\n",
      " [43], [52], [54]\n",
      "50%-latency:\n",
      " [18], [52], [51]\n",
      "75%-latency:\n",
      " [20], [72], [61]\n",
      "90%-latency:\n",
      " [73], [370], [280]\n",
      "95%-latency:\n",
      " [340], [600], [320]\n",
      "99%-latency:\n",
      " [6100], [6500], [6100]\n",
      "99.9%-latency:\n",
      " [6100], [6500], [6100]\n",
      "===== recommendation =====\n",
      "Average Response Time-latency:\n",
      " [45.67742811], [121.50552792], [114.0049635]\n",
      "Request Count-latency:\n",
      " [3686], [3618], [3425]\n",
      "50%-latency:\n",
      " [17], [52], [49]\n",
      "75%-latency:\n",
      " [20], [90], [84]\n",
      "90%-latency:\n",
      " [56], [350], [220]\n",
      "95%-latency:\n",
      " [93], [460], [400]\n",
      "99%-latency:\n",
      " [350], [600], [580]\n",
      "99.9%-latency:\n",
      " [5300], [5200], [6300]\n"
     ]
    }
   ],
   "source": [
    "API_PREFIX = \"/api/23bc46b1-71f6-4ed5-8c54-816aa4f8c502/\"\n",
    "\n",
    "evaluate_apis = [\n",
    "    \"/api/23bc46b1-71f6-4ed5-8c54-816aa4f8c502/hotelReservation/reservation\",\n",
    "    \"/api/23bc46b1-71f6-4ed5-8c54-816aa4f8c502/hotelReservation/search\",\n",
    "    \"/api/23bc46b1-71f6-4ed5-8c54-816aa4f8c502/hotelReservation/user\",\n",
    "    # \"/api/23bc46b1-71f6-4ed5-8c54-816aa4f8c502/hotelReservation/geo\",\n",
    "    # \"/api/23bc46b1-71f6-4ed5-8c54-816aa4f8c502/hotelReservation/profile\",\n",
    "    # \"/api/23bc46b1-71f6-4ed5-8c54-816aa4f8c502/hotelReservation/rate\",\n",
    "    \"/api/23bc46b1-71f6-4ed5-8c54-816aa4f8c502/hotelReservation/recommendation\"\n",
    "]\n",
    "metrics = [\"Average Response Time\", \"Request Count\",\n",
    "           \"50%\", '75%', '90%', '95%', '99%', '99.9%']\n",
    "for api in evaluate_apis:\n",
    "    short_api = api.replace(API_PREFIX, \"\")\n",
    "    api_interface = short_api.split(\"/\")[1]\n",
    "    print(f\"===== {api_interface} =====\")\n",
    "    api_hashcache = HashCache_data[HashCache_data['Name'] == api]\n",
    "    api_faascache = FaaSCache_data[FaaSCache_data['Name'] == api]\n",
    "    api_openwhisk = OpenWhisk_data[OpenWhisk_data['Name']==api]\n",
    "    for metric in metrics:\n",
    "        print(\n",
    "            f\"{metric}-latency:\\n {api_hashcache[metric].values}, {api_faascache[metric].values}, {api_openwhisk[metric].values}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "load-gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f8d660e60a2c0ba3d4fd9127d6b0ca2c20e366530ea84243e991b433f4cac20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
